{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nzrandolph/.miniconda3/envs/mpnn/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json, time, os\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import os.path\n",
    "import subprocess\n",
    "from vanilla_proteinmpnn.protein_mpnn_utils import _scores, _S_to_seq, tied_featurize, parse_PDB\n",
    "from vanilla_proteinmpnn.protein_mpnn_utils import StructureDataset, StructureDatasetPDB, ProteinMPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.path_to_model_weights = 'run/model_weights/'\n",
    "args.model_name = 'v_48_020'\n",
    "args.save_score = 0\n",
    "args.save_probs = 0\n",
    "args.score_only = 1\n",
    "args.conditional_probs_only = 0\n",
    "args.conditional_probs_only_backbone = 0\n",
    "args.unconditional_probs_only = 0\n",
    "args.backbone_noise = 0.00\n",
    "args.num_seq_per_target = 20\n",
    "args.batch_size = 20\n",
    "args.max_length = 20000\n",
    "args.sampling_temp = '0.1'\n",
    "args.out_folder = 'sandbox_outs/novozyme/'\n",
    "args.pdb_path = 'sandbox_outs/novozyme/wildtype_structure_prediction_af2.pdb'\n",
    "args.pdb_path_chains = ''\n",
    "args.jsonl_path = ''\n",
    "args.chain_id_jsonl = ''\n",
    "args.fixed_positions_jsonl = ''\n",
    "args.omit_AAs = 'X'\n",
    "args.bias_AA_jsonl = ''\n",
    "args.bias_by_res_jsonl = ''\n",
    "args.omit_AA_jsonl = ''\n",
    "args.pssm_jsonl = ''\n",
    "args.pssm_multi = 0.0\n",
    "args.pssm_threshold = 0.0\n",
    "args.pssm_log_odds_flag = 0\n",
    "args.pssm_bias_flag = 0\n",
    "args.tied_positions_jsonl = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.path_to_model_weights:\n",
    "    model_folder_path = args.path_to_model_weights\n",
    "    if model_folder_path[-1] != '/':\n",
    "        model_folder_path = model_folder_path + '/'\n",
    "else: \n",
    "    file_path = os.path.realpath(__file__)\n",
    "    k = file_path.rfind(\"/\")\n",
    "    model_folder_path = file_path[:k] + '/vanilla_model_weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = model_folder_path + f'{args.model_name}.pt'\n",
    "folder_for_outputs = args.out_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BATCHES = args.num_seq_per_target // args.batch_size\n",
    "BATCH_COPIES = args.batch_size\n",
    "temperatures = [float(temp) for temp in args.sampling_temp.split()]\n",
    "omit_AAs_list = args.omit_AAs\n",
    "alphabet = 'ACDEFGHIKLMNPQRSTVWYX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "omit_AAs_np = np.array([AA in omit_AAs_list for AA in alphabet]).astype(np.float32)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_file = 'sandbox_outs/novozyme/test.csv'\n",
    "with open(test_set_file, 'r') as f:\n",
    "    test_set_list = f.readlines()\n",
    "test_set = [mut.split(',')[:2] for mut in test_set_list[1:]]\n",
    "test_set_seqs = [mut[1] for mut in test_set]\n",
    "\n",
    "wt_seq = 'VPVNPEPDATSVENVALKTGSGDSQSDPIKADLEVKGQSALPFDVDCWAILCKGAPNVLQRVNEKTKNSNRDRSGANKGPF' \\\n",
    "         'KDPQKWGIKALPPKNPSWSAQDFKSPEEYAFASSLQGGTNAILAPVNLASQNSQGGVLNGFYSANKVAQFDPSKPQQTKGT' \\\n",
    "         'WFQITKFTGAAGPYCKALGSNDKSVCDKNKNIAGDWGFDPAKWAYQYDEKNNKFNYVGK'\n",
    "\n",
    "for i, seq in enumerate(test_set_seqs):\n",
    "    if len(seq) < len(wt_seq):\n",
    "        k = next((idx for idx, res in enumerate(seq) if res != wt_seq[idx]), None)\n",
    "        test_set_seqs[i] = seq[:k] + '-' + seq[k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "chain_id_jsonl is NOT loaded\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(args.chain_id_jsonl):\n",
    "    with open(args.chain_id_jsonl, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    for json_str in json_list:\n",
    "        chain_id_dict = json.loads(json_str)\n",
    "else:\n",
    "    chain_id_dict = None\n",
    "    print(40 * '-')\n",
    "    print('chain_id_jsonl is NOT loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "fixed_positions_jsonl is NOT loaded\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(args.fixed_positions_jsonl):\n",
    "    with open(args.fixed_positions_jsonl, 'r') as json_file:\n",
    "        json_list = list(json_list)\n",
    "    for json_str in json_list:\n",
    "        fixed_positions_dict = json.loads(json_str)\n",
    "else:\n",
    "    print(40 * '-')\n",
    "    print('fixed_positions_jsonl is NOT loaded')\n",
    "    fixed_positions_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "pssm_jsonl is NOT loaded\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(args.pssm_jsonl):\n",
    "    with open(args.pssm_jsonl, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    pssm_dict = {}\n",
    "    for json_str in json_list:\n",
    "        pssm_dict.update(json.loads(json_str))\n",
    "else:\n",
    "    print(40 * '-')\n",
    "    print('pssm_jsonl is NOT loaded')\n",
    "    pssm_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "omit_AA_jsonl is NOT loaded\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(args.omit_AA_jsonl):\n",
    "    with open(args.omit_AA_jsonl, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    for json_str in json_list:\n",
    "        omit_AA_dict = json.loads(json_str)\n",
    "else:\n",
    "    print(40 * '-')\n",
    "    print('omit_AA_jsonl is NOT loaded')\n",
    "    omit_AA_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "bias_AA_jsonl is NOT loaded\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(args.bias_AA_jsonl):\n",
    "    with open(args.bias_AA_jsonl, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    for json_str in json_list:\n",
    "        bias_AA_dict = json.loads(json_str)\n",
    "else:\n",
    "    print(40 * '-')\n",
    "    print('bias_AA_jsonl is NOT loaded')\n",
    "    bias_AA_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "tied_positions_jsonl is NOT loaded\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(args.tied_positions_jsonl):\n",
    "    with open(args.tied_positions_jsonl, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    for json_str in json_list:\n",
    "        tied_positions_dict = json.loads(json_str)\n",
    "else:\n",
    "    print(40 * '-')\n",
    "    print('tied_positions_jsonl is NOT loaded')\n",
    "    tied_positions_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "bias_by_res_jsonl is NOT loaded\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(args.bias_by_res_jsonl):\n",
    "    with open(args.bias_by_res_jsonl, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    for json_str in json_list:\n",
    "        bias_by_res_dict = json.loads(json_str)\n",
    "else:\n",
    "    print(40 * '-')\n",
    "    print('bias_by_res_jsonl is NOT loaded')\n",
    "    bias_by_res_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(40 * '-')\n",
    "bias_AAs_np = np.zeros(len(alphabet))\n",
    "if bias_AA_dict:\n",
    "    for n, AA in enumerate(alphabet):\n",
    "        if AA in list(bias_AA_dict.keys()):\n",
    "            bias_AAs_np[n] = bias_AA_dict[AA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.pdb_path:\n",
    "    pdb_dict_list = parse_PDB(args.pdb_path)\n",
    "    dataset_valid = StructureDatasetPDB(pdb_dict_list, truncate=None, max_length=args.max_length)\n",
    "    all_chain_list = [item[-1:] for item in list(pdb_dict_list[0]) if item[:9] == 'seq_chain']\n",
    "    if args.pdb_path_chains:\n",
    "        designed_chain_list = [str(item) for item in args.pdb_path_chains.split()]\n",
    "    else:\n",
    "        designed_chain_list = all_chain_list\n",
    "    fixed_chain_list = [letter for letter in all_chain_list if letter not in designed_chain_list]\n",
    "    chain_id_dict = {}\n",
    "    chain_id_dict[pdb_dict_list[0]['name']] = (designed_chain_list, fixed_chain_list)\n",
    "else:\n",
    "    dataset_valid = StructureDataset(args.jsonl_path, truncate=None, max_length=args.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Number of edges: 48\n",
      "Training noise_level: 0.2A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProteinMPNN(\n",
       "  (features): ProteinFeatures(\n",
       "    (embeddings): PositionalEncodings(\n",
       "      (linear): Linear(in_features=66, out_features=16, bias=True)\n",
       "    )\n",
       "    (edge_embedding): Linear(in_features=416, out_features=128, bias=False)\n",
       "    (norm_edges): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (W_e): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (W_s): Embedding(21, 128)\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0): EncLayer(\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (W1): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (W2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W11): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (W12): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W13): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (act): GELU(approximate=none)\n",
       "      (dense): PositionWiseFeedForward(\n",
       "        (W_in): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (W_out): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "      )\n",
       "    )\n",
       "    (1): EncLayer(\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (W1): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (W2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W11): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (W12): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W13): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (act): GELU(approximate=none)\n",
       "      (dense): PositionWiseFeedForward(\n",
       "        (W_in): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (W_out): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "      )\n",
       "    )\n",
       "    (2): EncLayer(\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (W1): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (W2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W11): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (W12): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W13): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (act): GELU(approximate=none)\n",
       "      (dense): PositionWiseFeedForward(\n",
       "        (W_in): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (W_out): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0): DecLayer(\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (W1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (W2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (act): GELU(approximate=none)\n",
       "      (dense): PositionWiseFeedForward(\n",
       "        (W_in): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (W_out): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "      )\n",
       "    )\n",
       "    (1): DecLayer(\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (W1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (W2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (act): GELU(approximate=none)\n",
       "      (dense): PositionWiseFeedForward(\n",
       "        (W_in): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (W_out): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "      )\n",
       "    )\n",
       "    (2): DecLayer(\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (W1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (W2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (act): GELU(approximate=none)\n",
       "      (dense): PositionWiseFeedForward(\n",
       "        (W_in): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (W_out): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (act): GELU(approximate=none)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (W_out): Linear(in_features=128, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(40 * '-')\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "print(f\"Number of edges: {checkpoint['num_edges']}\")\n",
    "noise_level_print = checkpoint['noise_level']\n",
    "print(f\"Training noise_level: {noise_level_print}A\")\n",
    "model = ProteinMPNN(num_letters=21, node_features=hidden_dim, edge_features=hidden_dim, hidden_dim=hidden_dim, num_encoder_layers=num_layers, num_decoder_layers=num_layers, augment_eps=args.backbone_noise, k_neighbors=checkpoint['num_edges'])\n",
    "model.to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = folder_for_outputs\n",
    "if base_folder[-1] != '/':\n",
    "    base_folder = base_folder + '/'\n",
    "\n",
    "if not os.path.exists(base_folder):\n",
    "    os.makedirs(base_folder)\n",
    "\n",
    "if not os.path.exists(base_folder + 'seqs'):\n",
    "    os.makedirs(base_folder + 'seqs')\n",
    "\n",
    "if args.save_score:\n",
    "    if not os.path.exists(base_folder + 'scores'):\n",
    "        os.makedirs(base_folder + 'scores')\n",
    "\n",
    "if args.score_only:\n",
    "    if not os.path.exists(base_folder + 'score_only'):\n",
    "        os.makedirs(base_folder + 'score_only')\n",
    "\n",
    "if args.conditional_probs_only:\n",
    "    if not os.path.exists(base_folder + 'conditional_probs_only'):\n",
    "        os.makedirs(base_folder + 'conditional_probs_only')\n",
    "\n",
    "if args.unconditional_probs_only:\n",
    "    if not os.path.exists(base_folder + 'unconditional_probs_only'):\n",
    "        os.makedirs(base_folder + 'unconditional_probs_only')\n",
    "\n",
    "if args.save_probs:\n",
    "    if not os.path.exists(base_folder + 'probs'):\n",
    "        os.makedirs(base_folder + 'probs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequences...\n"
     ]
    }
   ],
   "source": [
    "# Timing\n",
    "start_time = time.time()\n",
    "total_residues = 0\n",
    "protein_list = []\n",
    "total_step = 0\n",
    "\n",
    "# Validation epoch\n",
    "with torch.no_grad():\n",
    "\n",
    "    test_sum, test_weights = 0., 0.\n",
    "    print('Generating sequences...')\n",
    "    for ix, protein in enumerate(dataset_valid):\n",
    "\n",
    "        for i in range(len(test_set_seqs[:1])):\n",
    "            # Update the sequence with the mutated sequence\n",
    "            protein['seq_chain_A'] = test_set_seqs[i]\n",
    "            protein['seq'] = test_set_seqs[i]\n",
    "\n",
    "            # Form batch of clones\n",
    "            batch_clones = [copy.deepcopy(protein) for i in range(BATCH_COPIES)]\n",
    "            \n",
    "            # Featurize\n",
    "            X, S, mask, lengths, chain_M, chain_encoding_all, chain_list_list, visible_list_list, masked_list_list, masked_chain_length_list_list, chain_M_pos, omit_AA_mask, residue_idx, dihedral_mask, tied_pos_list_of_lists_list, pssm_coef, pssm_bias, pssm_log_odds_all, bias_by_res_all, tied_beta = tied_featurize(batch_clones, device, chain_id_dict, fixed_positions_dict, omit_AA_dict, tied_positions_dict, pssm_dict, bias_by_res_dict)\n",
    "            pssm_log_odds_mask = (pssm_log_odds_all > args.pssm_threshold).float() #1.0 for true, 0.0 for false\n",
    "            name_ = batch_clones[0]['name']\n",
    "            for j in range(NUM_BATCHES):\n",
    "                randn_1 = torch.randn(chain_M.shape, device=X.device)\n",
    "                log_probs = model(X, S, mask, chain_M * chain_M_pos, residue_idx, chain_encoding_all, randn_1)\n",
    "                mask_for_loss = mask * chain_M * chain_M_pos\n",
    "                score = torch.mean(_scores(S, log_probs, mask_for_loss))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mpnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce768abad0a4608467a7b0382c5c45f380a60f1068947e329b8f7fd1f458bd1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
